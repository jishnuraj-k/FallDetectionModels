{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bucSiiFYikS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Path to the folder containing the dataset\n",
        "dataset_folder = \"path/to/sisfall/dataset/folder\"\n",
        "\n",
        "# Path to the base output folder where the activity folders will be created\n",
        "output_folder = \"path/to/output/folder\"\n",
        "\n",
        "# List of activities\n",
        "activities = [\"stumble\", \"fall\", \"walk\", \"jump\"]\n",
        "\n",
        "# Iterate through each activity folder\n",
        "for activity in activities:\n",
        "    activity_folder = os.path.join(dataset_folder, activity)\n",
        "    \n",
        "    # Create a corresponding output folder for the activity\n",
        "    output_activity_folder = os.path.join(output_folder, activity)\n",
        "    os.makedirs(output_activity_folder, exist_ok=True)\n",
        "    \n",
        "    # Get the list of CSV files in the activity folder\n",
        "    csv_files = glob.glob(os.path.join(activity_folder, \"*.csv\"))\n",
        "    \n",
        "    # Iterate through each CSV file\n",
        "    for csv_file in csv_files:\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(csv_file)\n",
        "        \n",
        "        # Extract the first three accelerometer columns (change the column names if needed)\n",
        "        x_axis = df[\"x_axis\"]\n",
        "        y_axis = df[\"y_axis\"]\n",
        "        z_axis = df[\"z_axis\"]\n",
        "        \n",
        "        # Create a new figure\n",
        "        plt.figure()\n",
        "        \n",
        "        # Plot the accelerometer data\n",
        "        plt.plot(x_axis, label=\"X axis\")\n",
        "        plt.plot(y_axis, label=\"Y axis\")\n",
        "        plt.plot(z_axis, label=\"Z axis\")\n",
        "        \n",
        "        # Add labels and title\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Acceleration\")\n",
        "        plt.title(\"Accelerometer Data\")\n",
        "        \n",
        "        # Add legend\n",
        "        plt.legend()\n",
        "        \n",
        "        # Get the base name of the CSV file\n",
        "        base_name = os.path.basename(csv_file)\n",
        "        \n",
        "        # Save the graph image in the activity folder with a unique name\n",
        "        output_file = os.path.join(output_activity_folder, base_name + \".png\")\n",
        "        plt.savefig(output_file)\n",
        "        \n",
        "        # Close the figure\n",
        "        plt.close()\n",
        "\n",
        "print(\"Graph images generated and saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Path to the folder containing the generated graph images\n",
        "dataset_folder = \"path/to/generated/graph/images\"\n",
        "\n",
        "# Path to the output folder where the training and testing datasets will be saved\n",
        "output_folder = \"path/to/output/folder\"\n",
        "\n",
        "# Ratio of data to be allocated for training (0.8 = 80% training, 20% testing)\n",
        "train_ratio = 0.8\n",
        "\n",
        "# Create the training and testing folders\n",
        "train_folder = os.path.join(output_folder, \"train\")\n",
        "test_folder = os.path.join(output_folder, \"test\")\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "\n",
        "# Iterate through each activity folder\n",
        "for activity in os.listdir(dataset_folder):\n",
        "    activity_folder = os.path.join(dataset_folder, activity)\n",
        "    \n",
        "    # Create corresponding activity folders in the training and testing datasets\n",
        "    train_activity_folder = os.path.join(train_folder, activity)\n",
        "    test_activity_folder = os.path.join(test_folder, activity)\n",
        "    os.makedirs(train_activity_folder, exist_ok=True)\n",
        "    os.makedirs(test_activity_folder, exist_ok=True)\n",
        "    \n",
        "    # Get the list of graph image files for the current activity\n",
        "    graph_images = os.listdir(activity_folder)\n",
        "    \n",
        "    # Randomly shuffle the graph images\n",
        "    random.shuffle(graph_images)\n",
        "    \n",
        "    # Calculate the split index based on the train_ratio\n",
        "    split_index = int(len(graph_images) * train_ratio)\n",
        "    \n",
        "    # Split the graph images into training and testing datasets\n",
        "    train_images = graph_images[:split_index]\n",
        "    test_images = graph_images[split_index:]\n",
        "    \n",
        "    # Move the training images to the corresponding activity folder in the training dataset\n",
        "    for image in train_images:\n",
        "        source_path = os.path.join(activity_folder, image)\n",
        "        destination_path = os.path.join(train_activity_folder, image)\n",
        "        shutil.copy(source_path, destination_path)\n",
        "    \n",
        "    # Move the testing images to the corresponding activity folder in the testing dataset\n",
        "    for image in test_images:\n",
        "        source_path = os.path.join(activity_folder, image)\n",
        "        destination_path = os.path.join(test_activity_folder, image)\n",
        "        shutil.copy(source_path, destination_path)\n",
        "\n",
        "print(\"Dataset split into training and testing successfully!\")\n"
      ],
      "metadata": {
        "id": "q0o0nWY8YzWE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}